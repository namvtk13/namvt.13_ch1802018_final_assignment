{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chương trình: Face Recognition Mini-Challenge \n",
    "Nam Vũ - CH1802018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "# Introduction\n",
    "Chương trình dùng 3 thư viện chính:\n",
    "- cv2 (opencv): dùng để tìm khuôn mặt (face detection) trong ảnh và cắt vùng ảnh của khuôn mặt\n",
    "- tensorflow (TF): AI network để nhận dạng (recognize) khuôn mặt\n",
    "- PIL (pillow): dùng để hiển thị kết quả lên màn hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bên cạnh đó chương trình còn sử dụng một số thư viện khác\n",
    "- os : Sử dụng chủ yếu để xử lý các đường dẫn (path) của file và folder.\n",
    "- hashlib: sử dụng để tính MD5-hash của file, folder. Qua đó có thể kiểm tra một file hay thư mục có bị update hay không.\n",
    "- yaml: sử dụng để đọc/ghi file config của chương trình dưới dang yaml file (https://pyyaml.org/).\n",
    "- numpy: trong trương trình này không dùng numpy để tính toán mà chỉ sử dung đê lưu trữ data dưới cấu trúc array của numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import yaml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize program\n",
    "- Bật chức năng Eager-Execution của tensorflow cho phép thực thi tính toán ngay tức thì của TF (https://www.tensorflow.org/api_docs/python/tf/enable_eager_execution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Khai báo các hằng số được sử dụng trong chương trình\n",
    "  - IMG_WIDTH, IMG_HEIGHT: kích thước chuẩn của vùng khuôn mặt\n",
    "  - ALLOWED_EXTENSIONS: danh sách các loại ảnh mà chương trình hỗ trợ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "ALLOWED_EXTENSIONS = {'.png', '.jpg', '.jpeg', '.heic'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data_path: Thư mục chứa dữ liệu của chương trình. Bao gồm:\n",
    "  - hình ảnh để huấn luyện: database_imgs\n",
    "  - opencv model để detect khuôn mặt: opencv/data/haarcascades/haarcascade_frontalface_alt.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath(\"./data\")\n",
    "train_data_path = os.path.join(data_path, \"database_imgs\")\n",
    "face_cascade_name = os.path.join(data_path, \"opencv/data/haarcascades/haarcascade_frontalface_alt.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Đọc (load) model của opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier(face_cascade_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_names: đây là một array (toàn cục) chứa danh sách tên người (định danh) có trong bộ dữ liệu huấn luyện (training data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic functions\n",
    "Đây là các hàm cơ bản:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract_face\n",
    "    Hàm này dùng để trích xuất các khuôn mặt có trong một tấm ảnh. Hàm trả ra danh sách các vùng ảnh của các khuôn mặt được tìm thấy và vị trí của chúng trong ảnh gốc.\n",
    "    Hàm này được xây dựng dựa trên ví dụ của OPENCV về face-detection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input của hàm extract_face là đường dẫn của file hình chứa các khuôn mặt cần trích xuất.\n",
    "- Output của hàm là 2 array: array chứa các hình được trích xuất, và array chứa tọa độ (x, y, width, height) của hình ảnh.\n",
    "- Các hình trích xuât được chuẩn hóa về kích thước: 128x128 (IMG_WIDTH x IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(img_path):\n",
    "    \"\"\"\n",
    "    Extracts the list of faces from an input images\n",
    "    :param img_path: the path to image file. The input-file's extension must be in ALLOWED_EXTENSIONS\n",
    "    :return: 2 arrays: first array contains the image of faces, the second one contains the location (x, y, w, h)\n",
    "    \"\"\"\n",
    "\n",
    "    frame_ori = cv.imread(img_path)\n",
    "    frame_gra = cv.cvtColor(frame_ori, cv.COLOR_BGR2GRAY)\n",
    "    frame_gra = cv.equalizeHist(frame_gra)\n",
    "    faces = face_cascade.detectMultiScale(frame_gra)\n",
    "    img_faces = []\n",
    "    img_frame = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        frame_face = frame_gra[y:y + h, x:x + w]\n",
    "        frame_face = cv.resize(frame_face, dsize=(IMG_WIDTH, IMG_HEIGHT))\n",
    "        img_faces.append((frame_face / 127.5) - 1)\n",
    "        img_frame.append([x, y, w, h])\n",
    "    return img_faces, img_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_train_data\n",
    "Hàm này dùng để đọc nội dung folder chứa training data để cung cấp cho việc xây dựng model (build_model). \n",
    "Cấu trúc của training data đượ quy định theo đề bài:\n",
    "- Trong training data folder có nhiều sub-folder, folder-name là id của 1 người\n",
    "- Trong sub-folder chứa hình ảnh khuôn mặt tương ứng với folder-name\n",
    "Hàm này dùng hàm extract_face để trich xuất các khuôn mặt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input của hàm load_train_data là đường dẫn của folder chứa kho hình ảnh training.\n",
    "- Output của hàm là 1 array: mỗi phần tử trong array gồm 2 thành phần [ảnh khuôn mặt, định danh của ảnh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(train_dir):\n",
    "    \"\"\"\n",
    "    Load the content of training dir. It extracts the faces then create the pair of (data, label)\n",
    "    :param train_dir: the path to training dir\n",
    "    :return: an array which contains all pairs of (face-data, label)\n",
    "    \"\"\"\n",
    "\n",
    "    faces_data = []\n",
    "    if train_dir:\n",
    "        train_dir = train_dir.strip()\n",
    "    if not train_dir or not os.path.isdir(train_dir):\n",
    "        train_dir = \".\"\n",
    "    train_dir = os.path.abspath(train_dir)\n",
    "    for per in os.listdir(train_dir):\n",
    "        sub_dir = os.path.join(train_dir, per)\n",
    "        if os.path.isdir(sub_dir):\n",
    "            for img in os.listdir(sub_dir):\n",
    "                img_path = os.path.join(sub_dir, img)\n",
    "                if os.path.isfile(img_path):\n",
    "                    img_ext = os.path.splitext(img_path)[-1]\n",
    "                    if img_ext.lower() in ALLOWED_EXTENSIONS:\n",
    "                        faces = extract_face(img_path)[0]\n",
    "                        for f in faces:\n",
    "                            faces_data.append([f, per])\n",
    "    return faces_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build_model\n",
    "Đây là hàm sẽ xây dựng tensorflow's model từ kho hình ảnh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- b1. gọi hàm load_train_data đẻ đọc folder để có: train_images (danh sách hình ảnh) và train_names (danh sách định danh)\n",
    "- b2. Sử dụng numpy.array để chuẩn hóa (dimension) array trươc khi khởi tạo model (keras.Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    Builds the tensorflow model\n",
    "    :return: the tf-model\n",
    "    \"\"\"\n",
    "    global train_names\n",
    "    load_faces = load_train_data(train_data_path)\n",
    "    train_images = np.array([x[0] for x in load_faces], dtype=np.float32)\n",
    "    train_names = list(set([x[1] for x in load_faces]))\n",
    "    train_labels = np.array([train_names.index(x[1]) for x in load_faces], dtype=np.int)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(IMG_WIDTH, IMG_HEIGHT)),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(len(train_names), activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- b3. Khởi tạo model\n",
    "- b4. compile và fit model\n",
    "- b5. return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hash_md5_dir and hash_md5_file\n",
    "Đây là 2 hàm tính hash cho file và folder, các hàm này thường được dùng để kiểm tra sự thay đổi của 1 file hay 1 folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_md5_dir(dir_path):\n",
    "    \"\"\"\n",
    "    Calculates the mMD5 hash of a folder.\n",
    "    :param dir_path: the os path to folder\n",
    "    :return: MD5 string\n",
    "    \"\"\"\n",
    "    str_md5 = \"\"\n",
    "    if os.path.isdir(dir_path):\n",
    "        h = hashlib.sha1()\n",
    "        for name in sorted(os.listdir(dir_path)):\n",
    "            path_name = os.path.join(dir_path, name)\n",
    "            file_hash = \"\"\n",
    "            if os.path.isdir(path_name):\n",
    "                file_hash = hash_md5_dir(path_name)\n",
    "            else:\n",
    "                file_hash = hash_md5_file(path_name)\n",
    "            h.update(file_hash.encode('utf-8'))\n",
    "        str_md5 = h.hexdigest()\n",
    "    return str_md5\n",
    "\n",
    "\n",
    "def hash_md5_file(file_path):\n",
    "    \"\"\"\n",
    "    Calculates the mMD5 hash of file.\n",
    "    :param file_path: the os path to file\n",
    "    :return: MD5 string\n",
    "    \"\"\"\n",
    "    str_md5 = \"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        str_md5 = hashlib.md5(open(file_path, 'rb').read()).hexdigest()\n",
    "    return str_md5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recognize_face\n",
    "Đây là hàm dùng để định dạng khuôn măt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input hàm gồm 2 thành phần: tensorflow model và ảnh cần nhận dạng\n",
    "- Output: danh sách (array) các định danh tìm đươc và vị trí tương ứng (x, y, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_face(model, input_img):\n",
    "    \"\"\"\n",
    "    Recognize the name from the input image\n",
    "    :param model: the tf-model\n",
    "    :param input_img: the path to input image\n",
    "    :return: the list of names and their location\n",
    "    \"\"\"\n",
    "\n",
    "    faces = extract_face(input_img)\n",
    "    face_list = []\n",
    "    for i, f in enumerate(faces[0]):\n",
    "        predictions_single = model.predict(np.expand_dims(f, 0))\n",
    "        label = np.argmax(predictions_single[0])\n",
    "        face_list.append([train_names[label], faces[1][i]])\n",
    "\n",
    "    return face_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trong hàm này sử dụng model.predict để so sánh giữa 1 khuôn mặt trong ảnh input và training data trong model. Trong tất cả các đánh giá từ việc so sánh, thì lấy ra 1 kết quả có xác suất giống nhau cao nhất (sử dụng: numby.argmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init_program\n",
    "Đây là hàm sử lý tensorflow model khi chương trình bắt đầu chạy. Tensflow-model được training và lưu lại dạng file để lần chạy tiếp theo không cần re-train (nếu training-data không thay đổi) mà chỉ cần đọc từ file.\n",
    "Chương trình sử dụng 1 yaml file để lưu trữ một số kêt quả của lần chạy trước: data.yaml. Nội dung của data.yaml gồm 3 thành phần chính:\n",
    "- MD5 hash của training folder\n",
    "- Đường dẫn đến file lưu của model trong lần chạy trước\n",
    "- Danh sách định danh (tên người) trong training-data của lần chạy trước."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kiểm tra xem cần train lại model hay không: tính hash của training-folder và so sánh với hash của folder đó trong lần training trước, nếu 2 hash khác nhau tức là training data có sự thay đổi và cần re-train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_program(rebuild_flag=None):\n",
    "    \"\"\"\n",
    "    Initialize program\n",
    "    :param rebuild_flag: force to re-build model\n",
    "    :return: the tf model\n",
    "    \"\"\"\n",
    "    global train_names\n",
    "    key1 = \"data_hash\"\n",
    "    key2 = \"model_name\"\n",
    "    key3 = \"name_list\"\n",
    "    new_model = None\n",
    "    data_yaml = os.path.join(data_path, \"data.yaml\")\n",
    "    data_hash = \"\"\n",
    "    old_model_file = \"\"\n",
    "    \n",
    "\n",
    "    current_database_hash = hash_md5_dir(train_data_path)\n",
    "    if rebuild_flag:\n",
    "        new_model = True\n",
    "    else:\n",
    "        if os.path.exists(data_yaml):\n",
    "            data_config = yaml.load(open(data_yaml, \"rt\"))\n",
    "            if key1 in data_config and key2 in data_config and key3 in data_config:\n",
    "                data_hash = data_config[key1]\n",
    "                old_model_file = data_config[key2]\n",
    "                train_names = data_config[key3]\n",
    "            else:\n",
    "                new_model = True\n",
    "        else:\n",
    "            new_model = True\n",
    "        if not new_model:\n",
    "            if not data_hash or data_hash != current_database_hash:\n",
    "                new_model = True\n",
    "                \n",
    "\n",
    "    if not new_model and os.path.isfile(old_model_file):\n",
    "        # load model here\n",
    "        model = keras.models.load_model(old_model_file)\n",
    "    else:\n",
    "        if os.path.isfile(old_model_file):\n",
    "            os.remove(old_model_file)\n",
    "        model = build_model()\n",
    "        new_model_file = os.path.join(data_path, current_database_hash + \".model\")\n",
    "        data_config = {\n",
    "            key1: current_database_hash,\n",
    "            key2: new_model_file,\n",
    "            key3: train_names\n",
    "        }\n",
    "        try:\n",
    "            model.save(new_model_file)\n",
    "        except Exception as e:\n",
    "            print(\"Warning: error as saving tf-model. (%s)\" % e)\n",
    "        with open(data_yaml, 'w') as config_file:\n",
    "            yaml.dump(data_config, config_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu training data không thay đổi thì chương trình sẽ đọc model từ file lưu của lần training trước.\n",
    "ngược lại sẽ gọi hàm build_model để tạo model mới từ training-data, lưu model xuống file và update data.yaml file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display_result\n",
    "Hàm này dùng để hiển thị ảnh kết quả bao gồm ảnh gốc (cần nhận dạng) và tên (định danh) của các khuôn mặt định dạng được. Input của hàm này gồm 2 giấ trị:\n",
    "- đường dẫn của ảnh gốc\n",
    "- danh sách định danh và tọa độ tương ứng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(img_path, faces):\n",
    "    \"\"\"\n",
    "    Draw the images and recognized faces.\n",
    "    :param img_path: path of image\n",
    "    :param faces: recognized faces.\n",
    "    :return: nothing\n",
    "    \"\"\"\n",
    "    pil_image = Image.open(img_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "    txt_font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "    for name, (x, y, w, h) in faces:\n",
    "        draw.rectangle(((x, y), (x+w, y+h)), outline=(0, 255, 0), width=8)\n",
    "        text_w, text_h = draw.textsize(name, font=txt_font)\n",
    "        draw.rectangle(((x, y + h), (x + text_w + 10, y + h + text_h + 10)), fill=(0, 255, 0), outline=(0, 255, 0))\n",
    "        draw.text((x + 5, y + h + text_h - 5), name, fill=(255, 255, 255, 255), font=txt_font)\n",
    "    del draw\n",
    "    pil_image.show()\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](sample_results.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main\n",
    "main function của chương trình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\installed\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:22: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "(0, ['DUYETLV', [2574, 1076, 217, 217]])\n",
      "(1, ['TANTD', [1792, 880, 211, 211]])\n",
      "(2, ['DUYETLV', [1403, 1207, 288, 288]])\n",
      "(3, ['QUANVM', [225, 903, 255, 255]])\n",
      "(4, ['TANTD', [459, 1752, 300, 300]])\n",
      "(5, ['PHUONGTD', [1628, 1469, 371, 371]])\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    model = init_program()\n",
    "    data_test = \"./data/test_img/Feb 26- 2019 at 5-08 PM.HEIC\"\n",
    "    faces = recognize_face(model, data_test)\n",
    "    for f in enumerate(faces):\n",
    "        print(f)\n",
    "    display_result(data_test, faces)\n",
    "    return\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tóm tắt\n",
    "- Chương trình chỉ đạt mức độ demo, training do độ chính xác không cao.\n",
    "- Có 2 nguyên nhân chính của kết quả chưa đạt độ chính xác cao:\n",
    "-- Số lượng ảnh training quá ít cho 1 định danh (1 hoặc 2 ảnh)\n",
    "-- Chưa xây dựng được hàm rút trích đặc trưng của khuôn mặt, nên vector input cho training-model chưa thực sự tốt.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
