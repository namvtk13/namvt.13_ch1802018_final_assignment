{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chương trình: Face Recognition Mini-Challenge \n",
    "Nam Vũ - CH1802018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import yaml\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "## Giới thiệu:\n",
    "Chương trình dùng 3 thư viện chính:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\installed\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\installed\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\installed\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:122: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "(0, ['HOBV', [2574, 1076, 217, 217]])\n",
      "(1, ['PHUONGTD', [1792, 880, 211, 211]])\n",
      "(2, ['HOBV', [1403, 1207, 288, 288]])\n",
      "(3, ['TIENBDT', [225, 903, 255, 255]])\n",
      "(4, ['PHUONGTD', [459, 1752, 300, 300]])\n",
      "(5, ['PHUONGTD', [1628, 1469, 371, 371]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "ALLOWED_EXTENSIONS = {'.png', '.jpg', '.jpeg', '.heic'}\n",
    "\n",
    "data_path = os.path.abspath(\"./data\")\n",
    "face_cascade_name = os.path.join(data_path, \"opencv/data/haarcascades/haarcascade_frontalface_alt.xml\")\n",
    "face_cascade = cv.CascadeClassifier(face_cascade_name)\n",
    "train_data_path = os.path.join(data_path, \"database_imgs\")\n",
    "train_names = []\n",
    "\n",
    "\n",
    "def extract_face(img_path):\n",
    "    \"\"\"\n",
    "    Extracts the list of faces from an input images\n",
    "    :param img_path: the path to image file. The input-file's extension must be in ALLOWED_EXTENSIONS\n",
    "    :return: 2 arrays: first array contains the image of faces, the second one contains the location (x, y, w, h)\n",
    "    \"\"\"\n",
    "    frame_ori = cv.imread(img_path)\n",
    "    frame_gra = cv.cvtColor(frame_ori, cv.COLOR_BGR2GRAY)\n",
    "    frame_gra = cv.equalizeHist(frame_gra)\n",
    "    faces = face_cascade.detectMultiScale(frame_gra)\n",
    "    img_faces = []\n",
    "    img_frame = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        frame_face = frame_gra[y:y + h, x:x + w]\n",
    "        frame_face = cv.resize(frame_face, dsize=(IMG_HEIGHT, IMG_WIDTH))\n",
    "        img_faces.append((frame_face / 127.5) - 1)\n",
    "        img_frame.append([x, y, w, h])\n",
    "    return img_faces, img_frame\n",
    "\n",
    "\n",
    "def load_train_data(train_dir):\n",
    "    \"\"\"\n",
    "    Load the content of training dir. It extracts the faces then create the pair of (data, label)\n",
    "    :param train_dir: the path to training dir\n",
    "    :return: an array which contains all pairs of (data, label)\n",
    "    \"\"\"\n",
    "    faces_data = []\n",
    "    if train_dir:\n",
    "        train_dir = train_dir.strip()\n",
    "    if not train_dir or not os.path.isdir(train_dir):\n",
    "        train_dir = \".\"\n",
    "    train_dir = os.path.abspath(train_dir)\n",
    "    for per in os.listdir(train_dir):\n",
    "        sub_dir = os.path.join(train_dir, per)\n",
    "        if os.path.isdir(sub_dir):\n",
    "            for img in os.listdir(sub_dir):\n",
    "                img_path = os.path.join(sub_dir, img)\n",
    "                if os.path.isfile(img_path):\n",
    "                    img_ext = os.path.splitext(img_path)[-1]\n",
    "                    if img_ext.lower() in ALLOWED_EXTENSIONS:\n",
    "                        faces = extract_face(img_path)[0]\n",
    "                        for f in faces:\n",
    "                            faces_data.append([f, per])\n",
    "    return faces_data\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "    Builds the tensorflow model\n",
    "    :return: the tf-model\n",
    "    \"\"\"\n",
    "    global train_names\n",
    "    load_faces = load_train_data(train_data_path)\n",
    "    train_images = np.array([x[0] for x in load_faces], dtype=np.float32)\n",
    "    train_names = list(set([x[1] for x in load_faces]))\n",
    "    train_labels = np.array([train_names.index(x[1]) for x in load_faces], dtype=np.int)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(IMG_WIDTH, IMG_HEIGHT)),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(len(train_names), activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_images, train_labels, epochs=10)\n",
    "    return model\n",
    "\n",
    "\n",
    "def recognize_face(model, input_img):\n",
    "    \"\"\"\n",
    "    Recognize the name from the input image\n",
    "    :param model: the tf-model\n",
    "    :param input_img: the path to input image\n",
    "    :return: the list of names and their location\n",
    "    \"\"\"\n",
    "    faces = extract_face(input_img)\n",
    "    face_list = []\n",
    "    for i, f in enumerate(faces[0]):\n",
    "        predictions_single = model.predict(np.expand_dims(f, 0))\n",
    "        label = np.argmax(predictions_single[0])\n",
    "        face_list.append([train_names[label], faces[1][i]])\n",
    "    return face_list\n",
    "\n",
    "\n",
    "def init_program(rebuild_flag=None):\n",
    "    \"\"\"\n",
    "    Initialize program\n",
    "    :param rebuild_flag: force to re-build model\n",
    "    :return: the tf model\n",
    "    \"\"\"\n",
    "    global train_names\n",
    "    key1 = \"data_hash\"\n",
    "    key2 = \"model_name\"\n",
    "    key3 = \"name_list\"\n",
    "    new_model = None\n",
    "    data_yaml = os.path.join(data_path, \"data.yaml\")\n",
    "    data_hash = \"\"\n",
    "    old_model_file = \"\"\n",
    "    current_database_hash = hash_md5_dir(train_data_path)\n",
    "    if rebuild_flag:\n",
    "        new_model = True\n",
    "    else:\n",
    "        if os.path.exists(data_yaml):\n",
    "            data_config = yaml.load(open(data_yaml, \"rt\"))\n",
    "            if key1 in data_config and key2 in data_config and key3 in data_config:\n",
    "                data_hash = data_config[key1]\n",
    "                old_model_file = data_config[key2]\n",
    "                train_names = data_config[key3]\n",
    "            else:\n",
    "                new_model = True\n",
    "        else:\n",
    "            new_model = True\n",
    "        if not new_model:\n",
    "            if not data_hash or data_hash != current_database_hash:\n",
    "                new_model = True\n",
    "    if not new_model and os.path.isfile(old_model_file):\n",
    "        # load model here\n",
    "        model = keras.models.load_model(old_model_file)\n",
    "    else:\n",
    "        if os.path.isfile(old_model_file):\n",
    "            os.remove(old_model_file)\n",
    "        model = build_model()\n",
    "        new_model_file = os.path.join(data_path, current_database_hash + \".model\")\n",
    "        data_config = {\n",
    "            key1: current_database_hash,\n",
    "            key2: new_model_file,\n",
    "            key3: train_names\n",
    "        }\n",
    "        try:\n",
    "            model.save(new_model_file)\n",
    "        except Exception as e:\n",
    "            print(\"Warning: error as saving tf-model. (%s)\" % e)\n",
    "        with open(data_yaml, 'w') as config_file:\n",
    "            yaml.dump(data_config, config_file)\n",
    "    return model\n",
    "\n",
    "\n",
    "def hash_md5_dir(dir_path):\n",
    "    \"\"\"\n",
    "    Calculates the mMD5 hash of a folder.\n",
    "    :param dir_path: the os path to folder\n",
    "    :return: MD5 string\n",
    "    \"\"\"\n",
    "    str_md5 = \"\"\n",
    "    if os.path.isdir(dir_path):\n",
    "        h = hashlib.sha1()\n",
    "        for name in sorted(os.listdir(dir_path)):\n",
    "            path_name = os.path.join(dir_path, name)\n",
    "            file_hash = \"\"\n",
    "            if os.path.isdir(path_name):\n",
    "                file_hash = hash_md5_dir(path_name)\n",
    "            else:\n",
    "                file_hash = hash_md5_file(path_name)\n",
    "            h.update(file_hash.encode('utf-8'))\n",
    "        str_md5 = h.hexdigest()\n",
    "    return str_md5\n",
    "\n",
    "\n",
    "def hash_md5_file(file_path):\n",
    "    \"\"\"\n",
    "    Calculates the mMD5 hash of file.\n",
    "    :param file_path: the os path to file\n",
    "    :return: MD5 string\n",
    "    \"\"\"\n",
    "    str_md5 = \"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        str_md5 = hashlib.md5(open(file_path, 'rb').read()).hexdigest()\n",
    "    return str_md5\n",
    "\n",
    "\n",
    "def display_result(img_path, faces):\n",
    "    \"\"\"\n",
    "    Draw the images and recognized faces.\n",
    "    :param img_path: path of image\n",
    "    :param faces: recognized faces.\n",
    "    :return: nothing\n",
    "    \"\"\"\n",
    "    pil_image = Image.open(img_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "    txt_font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "    for name, (x, y, w, h) in faces:\n",
    "        draw.rectangle(((x, y), (x+w, y+h)), outline=(0, 255, 0), width=8)\n",
    "        text_w, text_h = draw.textsize(name, font=txt_font)\n",
    "        draw.rectangle(((x, y + h), (x + text_w + 10, y + h + text_h + 10)), fill=(0, 255, 0), outline=(0, 255, 0))\n",
    "        draw.text((x + 5, y + h + text_h - 5), name, fill=(255, 255, 255, 255), font=txt_font)\n",
    "    del draw\n",
    "    pil_image.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def main():\n",
    "    model = init_program()\n",
    "    data_test = \"./data/test_img/Feb 26- 2019 at 5-08 PM.HEIC\"\n",
    "    faces = recognize_face(model, data_test)\n",
    "    for f in enumerate(faces):\n",
    "        print(f)\n",
    "    display_result(data_test, faces)\n",
    "    return\n",
    "\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
